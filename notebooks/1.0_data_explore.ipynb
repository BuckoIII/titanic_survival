{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3749401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "import copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7843f896",
   "metadata": {},
   "source": [
    "### Plan:\n",
    "\n",
    "1. transform data\n",
    "1. use a logisitc regression model as a a baseline for prediciton of the trainng set\n",
    "1. use a mulit-layed layered neural network to predict a binary prediction fo survival for he training set\n",
    "\n",
    "#### compeition docs \n",
    "https://www.kaggle.com/competitions/titanic/data\n",
    "\n",
    "#### data\n",
    "data dictionary\n",
    "        Variable\tDefinition\tKey\n",
    "        survival\t- Survival\t0 = No, 1 = Yes\n",
    "        pclass - \tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "        sex\t- Sex\t\n",
    "        Age\t- Age in years\t\n",
    "        sibsp\t- # of siblings / spouses aboard the Titanic\t\n",
    "        parch\t- # of parents / children aboard the Titanic\t\n",
    "        ticket\t- Ticket number\t\n",
    "        fare\t- Passenger fare\t\n",
    "        cabin\t- Cabin number\t\n",
    "        embarked\t- Port of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "#### activation funciton:\n",
    "- layer 1 - Relu\n",
    "- output layer - sigmoid\n",
    "\n",
    "#### formulas:\n",
    "- logistic regression:\n",
    "        sigmoid(w.T x  + b)\n",
    "- sigmoid:\n",
    "        np.sigmoid()\n",
    "- relu:\n",
    "        np.maximum(arr, 0)\n",
    "- back propagation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd26c7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load training data\n",
    "\n",
    "DATA_PATH = Path('/Users/tommadden/Library/CloudStorage/OneDrive-petsathome.onmicrosoft.com/machine_learning_specialisation/titanic_survival/data')\n",
    "p = Path(DATA_PATH, 'titanic', 'train.csv')\n",
    "train_df = pd.read_csv(p, index_col=0)\n",
    "\n",
    "p = Path(DATA_PATH, 'titanic', 'test.csv')\n",
    "test_df = pd.read_csv(p, index_col=0)\n",
    "\n",
    "\n",
    "p = Path(DATA_PATH, 'titanic', 'gender_submission.csv')\n",
    "test_Y = pd.read_csv(p, index_col=0)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "95199d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass                                          Name     Sex  \\\n",
       "PassengerId                                                                 \n",
       "892               3                              Kelly, Mr. James    male   \n",
       "893               3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "894               2                     Myles, Mr. Thomas Francis    male   \n",
       "895               3                              Wirz, Mr. Albert    male   \n",
       "896               3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "              Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                       \n",
       "892          34.5      0      0   330911   7.8292   NaN        Q  \n",
       "893          47.0      1      0   363272   7.0000   NaN        S  \n",
       "894          62.0      0      0   240276   9.6875   NaN        Q  \n",
       "895          27.0      0      0   315154   8.6625   NaN        S  \n",
       "896          22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "70402ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "\n",
    "    # transform input parameters\n",
    "    input_df = df\n",
    "    \n",
    "    # sex classification: male = 1, female = 0\n",
    "    input_df['Sex'] = df.Sex.eq('male').mul(1)\n",
    "\n",
    "    # fill NaN age to average age (29.5)\n",
    "    input_df['Age'] = input_df['Age'].fillna(29.5)\n",
    "    \n",
    "    input_df.Cabin.fillna(0, inplace = True)\n",
    "    # set records with multiple cabin assignments to first cabin assingment (assumes this will not introduce bias)\n",
    "    input_df['CabinLevel'] = [i[0] if type(i) == list else i for i in input_df.Cabin.str.split().values]\n",
    "    # regex to isolate first letter of cabin name (presumed to be the level of the ship)\n",
    "    input_df['CabinLevel'] = [i[0] if type(i) == list else i for i in input_df.Cabin.str.findall(r'[A-Z]').values]\n",
    "\n",
    "    # cabin counts to columns\n",
    "    input_df['CabinLevel'].fillna(0, inplace = True)\n",
    "    levels = input_df['CabinLevel'].unique()\n",
    "    for i in levels:\n",
    "        input_df[str('CabinLevel'+str(i))] = np.where(input_df['CabinLevel'] == i, 1, 0)\n",
    "\n",
    "    # parse and store cabin number from cabin cloumn into canibno cloumn\n",
    "    input_df['CabinNo'] = [i[0] if type(i) == list else i for i in input_df.Cabin.str.split().values]\n",
    "\n",
    "    num_arr = input_df.CabinNo.str.findall(r'[0-9]+').values\n",
    "\n",
    "    CabinNoArr = []\n",
    "    for i in num_arr:\n",
    "        if type(i) == list:\n",
    "            try:\n",
    "              CabinNoArr.append(i[0])  \n",
    "            except:\n",
    "                CabinNoArr.append(i)\n",
    "        else:\n",
    "            CabinNoArr.append(i)\n",
    "\n",
    "    input_df['CabinNo'] = CabinNoArr    \n",
    "    input_df['CabinNo'].fillna(0, inplace=True)\n",
    "\n",
    "    # include only unwanted comlumns\n",
    "    filt = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch',\n",
    "           'Fare', 'CabinLevel0', 'CabinLevelC',\n",
    "           'CabinLevelE', 'CabinLevelG', 'CabinLevelD', 'CabinLevelA',\n",
    "           'CabinLevelB', 'CabinLevelF']\n",
    "    input_df = input_df[filt]\n",
    "\n",
    "    # exclude unwanted columns\n",
    "#     input_df = input_df.loc[:, ~input_df.columns.isin(['Survived','Name','Ticket', 'Embarked','Cabin','CabinLevel'])]\n",
    "\n",
    "    return input_df\n",
    "\n",
    "clean_train_df = clean_data(train_df)\n",
    "clean_train_Y = train_df['Survived']\n",
    "clean_test_df = clean_data(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "567451a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare',\n",
       "        'Cabin', 'Embarked', 'CabinLevel', 'CabinLevel0', 'CabinLevelB',\n",
       "        'CabinLevelE', 'CabinLevelA', 'CabinLevelC', 'CabinLevelD',\n",
       "        'CabinLevelF', 'CabinLevelG', 'CabinNo'],\n",
       "       dtype='object'),\n",
       " Index(['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket',\n",
       "        'Fare', 'Cabin', 'Embarked', 'CabinLevel', 'CabinLevel0', 'CabinLevelC',\n",
       "        'CabinLevelE', 'CabinLevelG', 'CabinLevelD', 'CabinLevelA',\n",
       "        'CabinLevelB', 'CabinLevelF', 'CabinLevelT', 'CabinNo'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns, train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c470244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_matrix(matrix, labels):\n",
    "    \n",
    "    # transform df variables to matrix\n",
    "\n",
    "    m = matrix.shape[0]\n",
    "    n = matrix.shape[1]\n",
    "\n",
    "    # pandas df to matrix & transpose so that there are 16 features and 891 training examples\n",
    "    # each column is a single training example, each column is a feature\n",
    "    matrix = matrix.values.T\n",
    "    labels = labels.values.reshape(1,m)\n",
    "\n",
    "    assert matrix.shape == (n,m) \n",
    "    assert labels.shape == (1,m)\n",
    "\n",
    "    print(matrix.shape, labels.shape)\n",
    "    \n",
    "    return matrix, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "36b0eaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 891) (1, 891)\n",
      "(14, 418) (1, 418)\n"
     ]
    }
   ],
   "source": [
    "# transform variables to matrix\n",
    "X_train, Y_train = df_to_matrix(clean_train_df, clean_train_Y)\n",
    "\n",
    "X_test, Y_test = df_to_matrix(clean_test_df, test_Y )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b0324683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notes\n",
    "arr = np.array([i * 0.01 for i in range(-10,10)])\n",
    "# tanh fucntion\n",
    "np.tanh(arr)\n",
    "\n",
    "# relu function\n",
    "np.maximum(arr,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "313df9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning specialisatoin logistic regression helper functions\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "\n",
    "    Arguments:\n",
    "    z -- A scalar or numpy array of any size.\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    \"\"\"\n",
    "    s = 1 / (1+np.exp(1)**-z)\n",
    "    return s\n",
    "\n",
    "\n",
    "\n",
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.\n",
    "    \n",
    "    Argument:\n",
    "    dim -- size of the w vector we want (or number of parameters in this case)\n",
    "    \n",
    "    Returns:\n",
    "    w -- initialized vector of shape (dim, 1)\n",
    "    b -- initialized scalar (corresponds to the bias) of type float\n",
    "    \"\"\"\n",
    "    \n",
    "    w = np.zeros(dim).reshape(dim,1)\n",
    "    b = 0.0\n",
    "\n",
    "    return w, b\n",
    "\n",
    "\n",
    "\n",
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function and its gradient for the propagation explained above\n",
    "\n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)\n",
    "\n",
    "    Return:\n",
    "    cost -- negative log-likelihood cost for logistic regression\n",
    "    dw -- gradient of the loss with respect to w, thus same shape as w\n",
    "    db -- gradient of the loss with respect to b, thus same shape as b\n",
    "    \n",
    "    Tips:\n",
    "    - Write your code step by step for the propagation. np.log(), np.dot()\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "\n",
    "    # forward propagation\n",
    "    A = sigmoid(np.dot(w.T.astype(float), X.astype(float)) + b)\n",
    "    cost = - np.mean(Y * np.log(A) + (1 - Y ) * np.log(1 - A))\n",
    "    \n",
    "    # back propagation\n",
    "    dw = 1/m * np.dot(X, (A-Y).T)\n",
    "    db = np.mean(A-Y)\n",
    "        \n",
    "    cost = np.squeeze(np.array(cost))\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost\n",
    "\n",
    "\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations=100, learning_rate=0.009, print_cost=False):\n",
    "    \"\"\"\n",
    "    This function optimizes w and b by running a gradient descent algorithm\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of shape (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- True to print the loss every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    params -- dictionary containing the weights w and bias b\n",
    "    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
    "    \n",
    "    Tips:\n",
    "    You basically need to write down two steps and iterate through them:\n",
    "        1) Calculate the cost and the gradient for the current parameters. Use propagate().\n",
    "        2) Update the parameters using gradient descent rule for w and b.\n",
    "    \"\"\"\n",
    "    \n",
    "    w = copy.deepcopy(w)\n",
    "    b = copy.deepcopy(b)\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        # Cost and gradient calculation \n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "                \n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update rule \n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "\n",
    "        \n",
    "        # Record the costs\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "            # Print the cost every 100 training iterations\n",
    "            if print_cost:\n",
    "                print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs\n",
    "\n",
    "\n",
    "\n",
    "def predict(w, b, X):\n",
    "    '''\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1, m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    # Compute vector \"A\" predicting the probabilities of yhat = y\n",
    "    \n",
    "    A = sigmoid(np.dot(w.T, X) + b) \n",
    "        \n",
    "    for i in range(A.shape[1]):\n",
    "        \n",
    "        # Convert probabilities A[0,i] to actual predictions p[0,i]\n",
    "        if A[0,i] >= 0.5 :\n",
    "            Y_prediction[0,i] = 1\n",
    "        else:\n",
    "            Y_prediction[0,i] = 0\n",
    "                    \n",
    "    return Y_prediction\n",
    "\n",
    "\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations=2000, learning_rate=0.5, print_cost=False):\n",
    "    \"\"\"\n",
    "    Builds the logistic regression model by calling the function you've implemented previously\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train)\n",
    "    Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)\n",
    "    X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test)\n",
    "    Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)\n",
    "    num_iterations -- hyperparameter representing the number of iterations to optimize the parameters\n",
    "    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()\n",
    "    print_cost -- Set to True to print the cost every 100 iterations\n",
    "    \n",
    "    Returns:\n",
    "    d -- dictionary containing information about the model.\n",
    "    \"\"\"\n",
    "    # initialize parameters with zeros \n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "\n",
    "    # calculates loss vs training set, calculates derivates and updates w & b\n",
    "    params, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)\n",
    "    \n",
    "    # updates w,b to optisied values\n",
    "    w = params['w']\n",
    "    b = params['b']\n",
    "    \n",
    "    # Predict test/train set examples\n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    " \n",
    "    # Print train/test Errors\n",
    "    if print_cost:\n",
    "        print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "        print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "610a84ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693147\n",
      "Cost after iteration 100: nan\n",
      "Cost after iteration 200: nan\n",
      "Cost after iteration 300: nan\n",
      "Cost after iteration 400: nan\n",
      "Cost after iteration 500: nan\n",
      "Cost after iteration 600: nan\n",
      "Cost after iteration 700: nan\n",
      "Cost after iteration 800: nan\n",
      "Cost after iteration 900: nan\n",
      "Cost after iteration 1000: nan\n",
      "Cost after iteration 1100: nan\n",
      "Cost after iteration 1200: nan\n",
      "Cost after iteration 1300: nan\n",
      "Cost after iteration 1400: nan\n",
      "Cost after iteration 1500: nan\n",
      "Cost after iteration 1600: nan\n",
      "Cost after iteration 1700: nan\n",
      "Cost after iteration 1800: nan\n",
      "Cost after iteration 1900: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xg/mm75c5z52274c3ylzwr2jg200000gp/T/ipykernel_914/4240751090.py:60: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = - np.mean(Y * np.log(A) + (1 - Y ) * np.log(1 - A))\n",
      "/var/folders/xg/mm75c5z52274c3ylzwr2jg200000gp/T/ipykernel_914/4240751090.py:60: RuntimeWarning: invalid value encountered in multiply\n",
      "  cost = - np.mean(Y * np.log(A) + (1 - Y ) * np.log(1 - A))\n",
      "/var/folders/xg/mm75c5z52274c3ylzwr2jg200000gp/T/ipykernel_914/4240751090.py:13: RuntimeWarning: overflow encountered in power\n",
      "  s = 1 / (1+np.exp(1)**-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 2000: nan\n",
      "Cost after iteration 2100: nan\n",
      "Cost after iteration 2200: nan\n",
      "Cost after iteration 2300: nan\n",
      "Cost after iteration 2400: nan\n",
      "Cost after iteration 2500: nan\n",
      "Cost after iteration 2600: nan\n",
      "Cost after iteration 2700: nan\n",
      "Cost after iteration 2800: nan\n",
      "Cost after iteration 2900: nan\n",
      "Cost after iteration 3000: nan\n",
      "Cost after iteration 3100: nan\n",
      "Cost after iteration 3200: nan\n",
      "Cost after iteration 3300: nan\n",
      "Cost after iteration 3400: nan\n",
      "Cost after iteration 3500: nan\n",
      "Cost after iteration 3600: nan\n",
      "Cost after iteration 3700: nan\n",
      "Cost after iteration 3800: nan\n",
      "Cost after iteration 3900: nan\n",
      "Cost after iteration 4000: nan\n",
      "Cost after iteration 4100: nan\n",
      "Cost after iteration 4200: nan\n",
      "Cost after iteration 4300: nan\n",
      "Cost after iteration 4400: nan\n",
      "Cost after iteration 4500: nan\n",
      "Cost after iteration 4600: nan\n",
      "Cost after iteration 4700: nan\n",
      "Cost after iteration 4800: nan\n",
      "Cost after iteration 4900: nan\n",
      "Cost after iteration 5000: nan\n",
      "Cost after iteration 5100: nan\n",
      "Cost after iteration 5200: nan\n",
      "Cost after iteration 5300: nan\n",
      "Cost after iteration 5400: nan\n",
      "Cost after iteration 5500: nan\n",
      "Cost after iteration 5600: nan\n",
      "Cost after iteration 5700: nan\n",
      "Cost after iteration 5800: nan\n",
      "Cost after iteration 5900: nan\n",
      "Cost after iteration 6000: nan\n",
      "Cost after iteration 6100: nan\n",
      "Cost after iteration 6200: nan\n",
      "Cost after iteration 6300: nan\n",
      "Cost after iteration 6400: nan\n",
      "Cost after iteration 6500: nan\n",
      "Cost after iteration 6600: nan\n",
      "Cost after iteration 6700: nan\n",
      "Cost after iteration 6800: nan\n",
      "Cost after iteration 6900: nan\n",
      "Cost after iteration 7000: nan\n",
      "Cost after iteration 7100: nan\n",
      "Cost after iteration 7200: nan\n",
      "Cost after iteration 7300: nan\n",
      "Cost after iteration 7400: nan\n",
      "Cost after iteration 7500: nan\n",
      "Cost after iteration 7600: nan\n",
      "Cost after iteration 7700: nan\n",
      "Cost after iteration 7800: nan\n",
      "Cost after iteration 7900: nan\n",
      "Cost after iteration 8000: nan\n",
      "Cost after iteration 8100: nan\n",
      "Cost after iteration 8200: nan\n",
      "Cost after iteration 8300: nan\n",
      "Cost after iteration 8400: nan\n",
      "Cost after iteration 8500: nan\n",
      "Cost after iteration 8600: nan\n",
      "Cost after iteration 8700: nan\n",
      "Cost after iteration 8800: nan\n",
      "Cost after iteration 8900: nan\n",
      "Cost after iteration 9000: nan\n",
      "Cost after iteration 9100: nan\n",
      "Cost after iteration 9200: nan\n",
      "Cost after iteration 9300: nan\n",
      "Cost after iteration 9400: nan\n",
      "Cost after iteration 9500: nan\n",
      "Cost after iteration 9600: nan\n",
      "Cost after iteration 9700: nan\n",
      "Cost after iteration 9800: nan\n",
      "Cost after iteration 9900: nan\n",
      "train accuracy: 76.87991021324355 %\n",
      "test accuracy: 88.99521531100478 %\n"
     ]
    }
   ],
   "source": [
    "# implement model\n",
    "\n",
    "log_model = model(X_train, Y_train, X_test, Y_test, num_iterations=10000, learning_rate=0.5, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "442acaf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'costs': [array(0.69314718)],\n",
       " 'Y_prediction_test': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "         1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "         1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "         0., 0.]]),\n",
       " 'Y_prediction_train': array([[0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "         0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "         1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
       "         0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "         1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
       "         1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
       "         0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " 'w': array([[-2.02861953e-01],\n",
       "        [-1.00729517e-01],\n",
       "        [-1.94145062e+00],\n",
       "        [-3.98428732e-02],\n",
       "        [-6.17283951e-03],\n",
       "        [ 1.23695553e+00],\n",
       "        [-7.71604938e-02],\n",
       "        [ 3.08641975e-03],\n",
       "        [ 4.48933782e-03],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 4.76992144e-03],\n",
       "        [-2.80583614e-04],\n",
       "        [ 6.45342312e-03],\n",
       "        [ 8.41750842e-04]]),\n",
       " 'b': -0.05808080808080808,\n",
       " 'learning_rate': 0.5,\n",
       " 'num_iterations': 1}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2999dc74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.    ,  3.    ,  2.    ,  3.    ,  3.    ,  3.    ],\n",
       "       [ 1.    ,  0.    ,  1.    ,  1.    ,  0.    ,  1.    ],\n",
       "       [34.5   , 47.    , 62.    , 27.    , 22.    , 14.    ],\n",
       "       [ 0.    ,  1.    ,  0.    ,  0.    ,  1.    ,  0.    ],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    ,  1.    ,  0.    ],\n",
       "       [ 7.8292,  7.    ,  9.6875,  8.6625, 12.2875,  9.225 ],\n",
       "       [ 1.    ,  1.    ,  1.    ,  1.    ,  1.    ,  1.    ],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_exp = X_test.T[0:6].T\n",
    "X_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d137f268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_exp = Y_test.T[0:6]\n",
    "Y_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "90cc2dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = log_model['w']\n",
    "b = log_model['b']\n",
    "\n",
    "# X_exp, Y_exp, w, b\n",
    "\n",
    "predict(w,b, X_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee9ba50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
